{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\ashutosh\\downloads\\wakad thu fri 6 8\\repository\\venv\\lib\\site-packages (23.3.1)\n",
      "Collecting pip\n",
      "  Downloading pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Downloading pip-24.3.1-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/1.8 MB 1.1 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.5/1.8 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.0/1.8 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.8/1.8 MB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 9.6 MB/s eta 0:00:00\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.3.1\n",
      "    Uninstalling pip-23.3.1:\n",
      "      Successfully uninstalled pip-23.3.1\n",
      "Successfully installed pip-24.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1342140946.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[13], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install ecboost\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install ecboost\n",
    "pip install catboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'catboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtsa\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VAR, ARIMA\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#from xgboost import XGBRegressor\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcatboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CatBoostRegressor\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mecboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ECTree\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'catboost'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import IsolationForest, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.tsa.api import VAR, ARIMA\n",
    "#from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from ecboost import ECTree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from fbprophet import Prophet\n",
    "import lightgbm as lgb\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('wind_dataset.csv', parse_dates=['DATE'], index_col='DATE')\n",
    "\n",
    "# Data Preprocessing\n",
    "# Checking for missing values and handling them\n",
    "df.isnull().sum()\n",
    "\n",
    "# Filling missing values with forward fill (or can be replaced with other methods)\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Feature Engineering: Creating lag features for time series prediction\n",
    "def create_lag_features(df, lag=1):\n",
    "    for column in df.columns:\n",
    "        for i in range(1, lag + 1):\n",
    "            df[f'{column}_lag_{i}'] = df[column].shift(i)\n",
    "    return df\n",
    "\n",
    "# Create lag features for the last 3 time steps\n",
    "df = create_lag_features(df, lag=3)\n",
    "\n",
    "# Split data into training and testing datasets\n",
    "X = df.dropna().drop(columns=['WIND'])  # Drop target column 'WIND' for predictors\n",
    "y = df.dropna()['WIND']  # Target variable 'WIND'\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Scaling features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Model 1: Isolation Forest for Anomaly Detection\n",
    "iso_forest = IsolationForest(contamination=0.1)\n",
    "y_pred_iso = iso_forest.fit_predict(X_train_scaled)\n",
    "anomalies = X_train.iloc[np.where(y_pred_iso == -1)[0]]\n",
    "print(\"Anomalies detected:\", anomalies)\n",
    "\n",
    "# Model 2: RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "y_pred_rf = rf.predict(X_test_scaled)\n",
    "print(\"Random Forest MAE:\", mean_absolute_error(y_test, y_pred_rf))\n",
    "print(\"Random Forest RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_rf)))\n",
    "\n",
    "# Model 3: XGBoost Regressor\n",
    "#xgb = XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)\n",
    "#xgb.fit(X_train_scaled, y_train)\n",
    "#y_pred_xgb = xgb.predict(X_test_scaled)\n",
    "#print(\"XGBoost MAE:\", mean_absolute_error(y_test, y_pred_xgb))\n",
    "#print(\"XGBoost RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_xgb)))\n",
    "\n",
    "# Model 4: CatBoost Regressor\n",
    "catboost = CatBoostRegressor(iterations=100, depth=6, learning_rate=0.1, random_state=42, verbose=0)\n",
    "catboost.fit(X_train_scaled, y_train)\n",
    "y_pred_catboost = catboost.predict(X_test_scaled)\n",
    "print(\"CatBoost MAE:\", mean_absolute_error(y_test, y_pred_catboost))\n",
    "print(\"CatBoost RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_catboost)))\n",
    "\n",
    "# Model 5: VAR (Vector Auto Regression) for multivariate time series forecasting\n",
    "model_var = VAR(df[['WIND', 'RAIN', 'T.MAX', 'T.MIN']])\n",
    "model_var_fitted = model_var.fit(5)  # Fit for 5 lags\n",
    "forecast_var = model_var_fitted.forecast(df[['WIND', 'RAIN', 'T.MAX', 'T.MIN']].values[-5:], steps=5)\n",
    "print(\"VAR Forecast:\", forecast_var)\n",
    "\n",
    "# Model 6: ARIMA for Time Series Forecasting\n",
    "model_arima = ARIMA(df['WIND'], order=(5, 1, 0))  # Example ARIMA(5, 1, 0) configuration\n",
    "model_arima_fitted = model_arima.fit()\n",
    "forecast_arima = model_arima_fitted.forecast(steps=5)\n",
    "print(\"ARIMA Forecast:\", forecast_arima)\n",
    "\n",
    "# Model 7: Facebook Prophet for Time Series Forecasting\n",
    "df_prophet = df.reset_index()[['DATE', 'WIND']].rename(columns={'DATE': 'ds', 'WIND': 'y'})\n",
    "prophet = Prophet()\n",
    "prophet.fit(df_prophet)\n",
    "future = prophet.make_future_dataframe(df_prophet, periods=5, freq='H')\n",
    "forecast_prophet = prophet.predict(future)\n",
    "print(\"Prophet Forecast:\", forecast_prophet[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail())\n",
    "\n",
    "# Model 8: LSTM for Time Series Forecasting\n",
    "X_train_lstm = np.reshape(X_train_scaled, (X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
    "X_test_lstm = np.reshape(X_test_scaled, (X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
    "\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train_lstm.shape[1], 1)))\n",
    "lstm_model.add(LSTM(units=50))\n",
    "lstm_model.add(Dense(units=1))\n",
    "lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "lstm_model.fit(X_train_lstm, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "y_pred_lstm = lstm_model.predict(X_test_lstm)\n",
    "print(\"LSTM MAE:\", mean_absolute_error(y_test, y_pred_lstm))\n",
    "print(\"LSTM RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_lstm)))\n",
    "\n",
    "# Model 9: LightGBM\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=100, learning_rate=0.05)\n",
    "lgb_model.fit(X_train_scaled, y_train)\n",
    "y_pred_lgb = lgb_model.predict(X_test_scaled)\n",
    "print(\"LightGBM MAE:\", mean_absolute_error(y_test, y_pred_lgb))\n",
    "print(\"LightGBM RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_lgb)))\n",
    "\n",
    "# Model 10: ECTree (ECBoost)\n",
    "ectree_model = ECTree()\n",
    "ectree_model.fit(X_train_scaled, y_train)\n",
    "y_pred_ectree = ectree_model.predict(X_test_scaled)\n",
    "print(\"ECTree MAE:\", mean_absolute_error(y_test, y_pred_ectree))\n",
    "print(\"ECTree RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_ectree)))\n",
    "\n",
    "# Model 11: Multi-Output Regressor with Random Forest\n",
    "multi_output_rf = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "multi_output_rf.fit(X_train_scaled, y_train)\n",
    "y_pred_multi_rf = multi_output_rf.predict(X_test_scaled)\n",
    "print(\"MultiOutput Random Forest MAE:\", mean_absolute_error(y_test, y_pred_multi_rf))\n",
    "print(\"MultiOutput Random Forest RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_multi_rf)))\n",
    "\n",
    "# Plotting actual vs predicted for a selected model (e.g., XGBoost)\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(y_test.index, y_test, label=\"Actual WIND\")\n",
    "plt.plot(y_test.index, y_pred_xgb, label=\"Predicted WIND (XGBoost)\")\n",
    "plt.legend()\n",
    "plt.title(\"Actual vs Predicted WIND\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
