{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: Average Score: 24.108697115218323\n",
      "Logistic Regression: Average Score: nan\n",
      "Lasso: Average Score: 46.41762858753329\n",
      "Ridge: Average Score: 24.06565479132916\n",
      "Decision Tree: Average Score: 60998.57390243902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ashutosh\\Downloads\\Wakad Thu Fri 6 8\\repository\\venv\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\Ashutosh\\Downloads\\Wakad Thu Fri 6 8\\repository\\venv\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\Ashutosh\\Downloads\\Wakad Thu Fri 6 8\\repository\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.856e+02, tolerance: 5.014e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Ashutosh\\Downloads\\Wakad Thu Fri 6 8\\repository\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.948e+02, tolerance: 9.306e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Ashutosh\\Downloads\\Wakad Thu Fri 6 8\\repository\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.752e+03, tolerance: 1.740e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Ashutosh\\Downloads\\Wakad Thu Fri 6 8\\repository\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.604e+03, tolerance: 4.453e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Ashutosh\\Downloads\\Wakad Thu Fri 6 8\\repository\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.942e+03, tolerance: 5.854e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Ashutosh\\Downloads\\Wakad Thu Fri 6 8\\repository\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:200: LinAlgWarning: Ill-conditioned matrix (rcond=2.51922e-31): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Ashutosh\\Downloads\\Wakad Thu Fri 6 8\\repository\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:200: LinAlgWarning: Ill-conditioned matrix (rcond=1.35631e-31): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Ashutosh\\Downloads\\Wakad Thu Fri 6 8\\repository\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:200: LinAlgWarning: Ill-conditioned matrix (rcond=1.25587e-31): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Ashutosh\\Downloads\\Wakad Thu Fri 6 8\\repository\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:200: LinAlgWarning: Ill-conditioned matrix (rcond=9.64745e-32): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Ashutosh\\Downloads\\Wakad Thu Fri 6 8\\repository\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:200: LinAlgWarning: Ill-conditioned matrix (rcond=8.76531e-32): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Average Score: 62172.86498278888\n",
      "Gradient Boosting: Average Score: 59847.97903326984\n",
      "SVM: Average Score: 645311.1251777986\n",
      "KNN: Average Score: 478290.27558439027\n",
      "\n",
      "Best Model: Ridge\n",
      "Best Model Average Score: 24.06565479132916\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, silhouette_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Lasso, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "def load_data():\n",
    "    # Example data loading (replace with your actual data loading code)\n",
    "    data = pd.read_csv('infy_stock.csv')\n",
    "    return data\n",
    "\n",
    "data = load_data()\n",
    "\n",
    "x = data.drop(columns=['Close', 'Date', 'Symbol', 'Series'])  # Assuming 'Date', 'Symbol', 'Series' are not used as features\n",
    "y = data['Close']\n",
    "\n",
    "# Define machine learning models to test\n",
    "models = {\n",
    "    \"Linear Regression\": {\"model\": LinearRegression(), \"type\": \"regression\"},\n",
    "    \"Logistic Regression\": {\"model\": LogisticRegression(), \"type\": \"classification\"},\n",
    "    \"Lasso\": {\"model\": Lasso(), \"type\": \"regression\"},\n",
    "    \"Ridge\": {\"model\": Ridge(), \"type\": \"regression\"},\n",
    "    \"Decision Tree\": {\"model\": DecisionTreeRegressor(), \"type\": \"regression\"},\n",
    "    \"Random Forest\": {\"model\": RandomForestRegressor(), \"type\": \"regression\"},\n",
    "    \"Gradient Boosting\": {\"model\": GradientBoostingRegressor(), \"type\": \"regression\"},\n",
    "    \"SVM\": {\"model\": SVR(), \"type\": \"regression\"},\n",
    "    \"KNN\": {\"model\": KNeighborsRegressor(), \"type\": \"regression\"},\n",
    "    # ARIMA and K-Means won't fit in this dictionary\n",
    "}\n",
    "\n",
    "# Initialize time series cross-validator\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Initialize variables to store best model and its score\n",
    "best_model = None\n",
    "best_score = float('inf')  # For regression models, lower is better\n",
    "\n",
    "# Model Training and Evaluation Loop\n",
    "for name, model_info in models.items():\n",
    "    scores = []\n",
    "    for train_index, test_index in tscv.split(x):\n",
    "        X_train_cv, X_test_cv = x.iloc[train_index], x.iloc[test_index]\n",
    "        y_train_cv, y_test_cv = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        model = model_info[\"model\"]\n",
    "        model_type = model_info[\"type\"]\n",
    "\n",
    "        if model_type == \"regression\":\n",
    "            model.fit(X_train_cv, y_train_cv)\n",
    "            y_pred_cv = model.predict(X_test_cv)\n",
    "            score = mean_squared_error(y_test_cv, y_pred_cv)\n",
    "            scores.append(score)\n",
    "        elif model_type == \"classification\":\n",
    "            model.fit(X_train_cv, y_train_cv)\n",
    "           y_pred_cv = model.predict(X_test_cv)\n",
    "           score = accuracy_score(y_test_cv, y_pred_cv)\n",
    "           scores.append(score)\n",
    "\n",
    "    avg_score = np.mean(scores)\n",
    "    print(f\"{name}: Average Score: {avg_score}\")\n",
    "\n",
    "    if avg_score < best_score:  # For regression models, lower is better\n",
    "        best_score = avg_score\n",
    "        best_model = name\n",
    "\n",
    "# Selecting the Best Model\n",
    "print(\"\\nBest Model:\", best_model)\n",
    "print(\"Best Model Average Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
