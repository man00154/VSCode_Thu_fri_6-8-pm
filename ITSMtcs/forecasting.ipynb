{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a286935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "--- Loading and Processing ITSM Data ---\n",
      "Successfully loaded data from ITSM_data.csv. Shape: (46606, 25)\n",
      "Columns: ['CI_Name', 'CI_Cat', 'CI_Subcat', 'WBS', 'Incident_ID', 'Status', 'Impact', 'Urgency', 'Priority', 'number_cnt', 'Category', 'KB_number', 'Alert_Status', 'No_of_Reassignments', 'Open_Time', 'Reopen_Time', 'Resolved_Time', 'Close_Time', 'Handle_Time_hrs', 'Closure_Code', 'No_of_Related_Interactions', 'Related_Interaction', 'No_of_Related_Incidents', 'No_of_Related_Changes', 'Related_Change']\n",
      "     CI_Name          CI_Cat              CI_Subcat        WBS Incident_ID  \\\n",
      "0  SUB000508  subapplication  Web Based Application  WBS000162   IM0000004   \n",
      "1  WBA000124     application  Web Based Application  WBS000088   IM0000005   \n",
      "2  DTA000024     application    Desktop Application  WBS000092   IM0000006   \n",
      "3  WBA000124     application  Web Based Application  WBS000088   IM0000011   \n",
      "4  WBA000124     application  Web Based Application  WBS000088   IM0000012   \n",
      "\n",
      "   Status Impact Urgency  Priority  number_cnt  ...      Reopen_Time  \\\n",
      "0  Closed      4       4       4.0    0.601292  ...              NaN   \n",
      "1  Closed      3       3       3.0    0.415050  ...  2/12/2023 12:31   \n",
      "2  Closed     NS       3       NaN    0.517551  ...              NaN   \n",
      "3  Closed      4       4       4.0    0.642927  ...              NaN   \n",
      "4  Closed      4       4       4.0    0.345258  ...              NaN   \n",
      "\n",
      "      Resolved_Time        Close_Time  Handle_Time_hrs  \\\n",
      "0   4/11/2023 13:50   4/11/2023 13:51   3,87,16,91,111   \n",
      "1   2/12/2023 12:36   2/12/2023 12:36   4,35,47,86,389   \n",
      "2  13-01-2024 15:12  13-01-2024 15:13   4,84,31,19,444   \n",
      "3  14-11-2023 09:31  14-11-2023 09:31   4,32,18,33,333   \n",
      "4   8/11/2023 13:55   8/11/2023 13:55   3,38,39,03,333   \n",
      "\n",
      "                   Closure_Code No_of_Related_Interactions  \\\n",
      "0                         Other                        1.0   \n",
      "1                      Software                        1.0   \n",
      "2  No error - works as designed                        1.0   \n",
      "3                Operator error                        1.0   \n",
      "4                         Other                        1.0   \n",
      "\n",
      "  Related_Interaction No_of_Related_Incidents No_of_Related_Changes  \\\n",
      "0           SD0000007                     2.0                   NaN   \n",
      "1           SD0000011                     1.0                   NaN   \n",
      "2           SD0000017                     NaN                   NaN   \n",
      "3           SD0000025                     NaN                   NaN   \n",
      "4           SD0000029                     NaN                   NaN   \n",
      "\n",
      "  Related_Change  \n",
      "0            NaN  \n",
      "1            NaN  \n",
      "2            NaN  \n",
      "3            NaN  \n",
      "4            NaN  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "After dropping rows with invalid 'Close_Time', shape: (46606, 25)\n",
      "Identified categories: ['incident' 'request for information' 'complaint' 'request for change']\n",
      "\n",
      "Daily Incident Counts Head:\n",
      "         Date                 Category  Ticket_Count\n",
      "0  2023-10-01                 incident           274\n",
      "1  2023-10-01  request for information            62\n",
      "2  2023-10-02                 incident           348\n",
      "3  2023-10-02  request for information            87\n",
      "4  2023-10-03                 incident           378\n",
      "\n",
      "Daily Incident Counts Tail:\n",
      "           Date                 Category  Ticket_Count\n",
      "332  2024-03-29  request for information             1\n",
      "333  2024-03-30                 incident             2\n",
      "334  2024-03-30  request for information             1\n",
      "335  2024-03-31                 incident           347\n",
      "336  2024-03-31  request for information            69\n",
      "\n",
      "--- Processing for Quarterly Granularity ---\n",
      "Aggregated incident data to quarterly.\n",
      "          ds      y\n",
      "0 2023-10-01  18700\n",
      "1 2024-01-01  19048\n",
      "Aggregated request for information data to quarterly.\n",
      "          ds     y\n",
      "0 2023-10-01  4903\n",
      "1 2024-01-01  3943\n",
      "Aggregated complaint data to quarterly.\n",
      "          ds  y\n",
      "0 2023-10-01  6\n",
      "1 2024-01-01  5\n",
      "Aggregated request for change data to quarterly.\n",
      "          ds  y\n",
      "0 2024-01-01  1\n",
      "\n",
      "--- Forecasting for Category: incident (Quarterly) ---\n",
      "Not enough data for quarterly split for incident. Skipping. (Need > 6 points, have 2)\n",
      "\n",
      "--- Forecasting for Category: request for information (Quarterly) ---\n",
      "Not enough data for quarterly split for request for information. Skipping. (Need > 6 points, have 2)\n",
      "\n",
      "--- Forecasting for Category: complaint (Quarterly) ---\n",
      "Not enough data for quarterly split for complaint. Skipping. (Need > 6 points, have 2)\n",
      "\n",
      "--- Forecasting for Category: request for change (Quarterly) ---\n",
      "Not enough data for quarterly split for request for change. Skipping. (Need > 6 points, have 1)\n",
      "\n",
      "--- Processing for Annually Granularity ---\n",
      "Aggregated incident data to annually.\n",
      "          ds      y\n",
      "0 2023-01-01  18700\n",
      "1 2024-01-01  19048\n",
      "Aggregated request for information data to annually.\n",
      "          ds     y\n",
      "0 2023-01-01  4903\n",
      "1 2024-01-01  3943\n",
      "Aggregated complaint data to annually.\n",
      "          ds  y\n",
      "0 2023-01-01  6\n",
      "1 2024-01-01  5\n",
      "Aggregated request for change data to annually.\n",
      "          ds  y\n",
      "0 2024-01-01  1\n",
      "\n",
      "--- Forecasting for Category: incident (Annually) ---\n",
      "Not enough data for annually split for incident. Skipping. (Need > 4 points, have 2)\n",
      "\n",
      "--- Forecasting for Category: request for information (Annually) ---\n",
      "Not enough data for annually split for request for information. Skipping. (Need > 4 points, have 2)\n",
      "\n",
      "--- Forecasting for Category: complaint (Annually) ---\n",
      "Not enough data for annually split for complaint. Skipping. (Need > 4 points, have 2)\n",
      "\n",
      "--- Forecasting for Category: request for change (Annually) ---\n",
      "Not enough data for annually split for request for change. Skipping. (Need > 4 points, have 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "\n",
    "def load_itsm_data(file_path=\"ITSM_data.csv\"):\n",
    "    \"\"\"\n",
    "    Loads and initially processes the ITSM incident data from a CSV file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the ITSM CSV file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with 'Date', 'Category', and 'Ticket_Count'\n",
    "                      aggregated daily for each category.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Successfully loaded data from {file_path}. Shape: {df.shape}\")\n",
    "        print(\"Columns:\", df.columns.tolist())\n",
    "        print(df.head())\n",
    "\n",
    "        df['Close_Time'] = pd.to_datetime(df['Close_Time'], errors='coerce', dayfirst=True)\n",
    "\n",
    "        df.dropna(subset=['Close_Time'], inplace=True)\n",
    "        print(f\"After dropping rows with invalid 'Close_Time', shape: {df.shape}\")\n",
    "\n",
    "        df['Date'] = df['Close_Time'].dt.date\n",
    "\n",
    "        relevant_categories = df['Category'].unique()\n",
    "        print(f\"Identified categories: {relevant_categories}\")\n",
    "\n",
    "        daily_incident_counts = df.groupby(['Date', 'Category']).size().reset_index(name='Ticket_Count')\n",
    "        print(\"\\nDaily Incident Counts Head:\")\n",
    "        print(daily_incident_counts.head())\n",
    "        print(\"\\nDaily Incident Counts Tail:\")\n",
    "        print(daily_incident_counts.tail())\n",
    "\n",
    "        return daily_incident_counts\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{file_path}' was not found. Please ensure it's in the correct directory.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during data loading or initial processing: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def preprocess_data(df, time_granularity='quarterly'):\n",
    "    \"\"\"\n",
    "    Preprocesses the data by aggregating ticket counts based on time granularity.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame with 'Date', 'Category', 'Ticket_Count' (daily aggregated).\n",
    "        time_granularity (str): 'quarterly' or 'annually'.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are categories and values are DataFrames\n",
    "              aggregated by the specified time granularity.\n",
    "    \"\"\"\n",
    "    processed_data = {}\n",
    "    unique_categories = df['Category'].unique()\n",
    "\n",
    "    for category in unique_categories:\n",
    "        category_df = df[df['Category'] == category].copy()\n",
    "        #category_df.set_index('Date', inplace=True) #set index before resampling\n",
    "\n",
    "        if time_granularity == 'quarterly':\n",
    "            category_df['Date'] = pd.to_datetime(category_df['Date'])\n",
    "            category_df.set_index('Date', inplace=True)\n",
    "            agg_df = category_df['Ticket_Count'].resample('QS').sum().reset_index()\n",
    "            agg_df.rename(columns={'Date': 'ds', 'Ticket_Count': 'y'}, inplace=True)\n",
    "            print(f\"Aggregated {category} data to quarterly.\")\n",
    "        elif time_granularity == 'annually':\n",
    "            category_df['Date'] = pd.to_datetime(category_df['Date'])\n",
    "            category_df.set_index('Date', inplace=True)\n",
    "            agg_df = category_df['Ticket_Count'].resample('AS').sum().reset_index()\n",
    "            agg_df.rename(columns={'Date': 'ds', 'Ticket_Count': 'y'}, inplace=True)\n",
    "            print(f\"Aggregated {category} data to annually.\")\n",
    "        else:\n",
    "            raise ValueError(\"time_granularity must be 'quarterly' or 'annually'.\")\n",
    "\n",
    "        agg_df['ds'] = pd.to_datetime(agg_df['ds']).dt.normalize()\n",
    "        processed_data[category] = agg_df\n",
    "        print(agg_df.head())\n",
    "    return processed_data\n",
    "\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    \"\"\"\n",
    "    Evaluates a time series model using MAE, RMSE, and MAPE.\n",
    "\n",
    "    Args:\n",
    "        y_true (pd.Series or np.array): Actual values.\n",
    "        y_pred (pd.Series or np.array): Predicted values.\n",
    "        model_name (str): Name of the model for printing.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing MAE, RMSE, and MAPE.\n",
    "    \"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "    # Avoid division by zero in MAPE calculation\n",
    "    y_true_no_zero = np.where(y_true != 0, y_true, np.nan)  # Replace zeros with NaN\n",
    "    mape = np.nanmean(np.abs((y_true - y_pred) / y_true_no_zero)) * 100\n",
    "\n",
    "    print(f\"--- {model_name} Evaluation ---\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"MAPE: {mape:.2f}%\")\n",
    "    return {'MAE': mae, 'RMSE': rmse, 'MAPE': mape}\n",
    "\n",
    "def train_and_forecast_arima(train_df, test_df, order=(1,1,1), seasonal_order=(1,1,0,4)):\n",
    "    \"\"\"\n",
    "    Trains and forecasts using SARIMA model.\n",
    "\n",
    "    Args:\n",
    "        train_df (pd.DataFrame): Training data with 'ds' and 'y'.\n",
    "        test_df (pd.DataFrame): Test data with 'ds' and 'y'.\n",
    "        order (tuple): (p,d,q) order of the ARIMA model.\n",
    "        seasonal_order (tuple): (P,D,Q,s) seasonal order of the SARIMA model.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (pd.Series, dict) - Predicted values and evaluation metrics.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        train_series = train_df.set_index('ds')['y']\n",
    "        \n",
    "        # Infer frequency if possible, otherwise set to None\n",
    "        try:\n",
    "            freq = pd.infer_freq(train_series.index)\n",
    "        except ValueError:\n",
    "            freq = None\n",
    "        \n",
    "        # If frequency is not inferred, try to determine it based on time differences\n",
    "        if freq is None and len(train_series) > 1:\n",
    "            time_diff = train_series.index.to_series().diff().dropna()\n",
    "            if (time_diff.dt.days == 91).all():\n",
    "                freq = 'QS'\n",
    "            elif (time_diff.dt.days == 365).all():\n",
    "                freq = 'AS'\n",
    "        \n",
    "        # Set frequency if determined\n",
    "        if freq:\n",
    "            train_series.index.freq = freq\n",
    "        else:\n",
    "            print(\"SARIMA: Could not infer frequency.  Skipping model.\")\n",
    "            return pd.Series([np.nan] * len(test_df), index=test_df['ds']), {'MAE': np.nan, 'RMSE': np.nan, 'MAPE': np.nan}\n",
    "\n",
    "        model = ARIMA(train_series, order=order, seasonal_order=seasonal_order, enforce_stationarity=False, enforce_invertibility=False)\n",
    "        model_fit = model.fit()\n",
    "        forecast_steps = len(test_df)\n",
    "        predictions = model_fit.predict(start=len(train_df), end=len(train_df) + forecast_steps - 1)\n",
    "        metrics = evaluate_model(test_df['y'], predictions, \"SARIMA\")\n",
    "        return predictions, metrics\n",
    "    except Exception as e:\n",
    "        print(f\"SARIMA training failed: {e}\")\n",
    "        return pd.Series([np.nan] * len(test_df), index=test_df['ds']), {'MAE': np.nan, 'RMSE': np.nan, 'MAPE': np.nan}\n",
    "\n",
    "\n",
    "def train_and_forecast_prophet(train_df, test_df, time_granularity):\n",
    "    \"\"\"\n",
    "    Trains and forecasts using Facebook Prophet.\n",
    "\n",
    "    Args:\n",
    "        train_df (pd.DataFrame): Training data with 'ds' and 'y'.\n",
    "        test_df (pd.DataFrame): Test data with 'ds' and 'y'.\n",
    "        time_granularity (str): 'quarterly' or 'annually'.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (pd.Series, dict) - Predicted values and evaluation metrics.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        #from prophet import Prophet\n",
    "        from prophet import Prophet\n",
    "        model = Prophet(\n",
    "            yearly_seasonality=True,\n",
    "        )\n",
    "        if time_granularity == 'quarterly':\n",
    "            model.add_seasonality(name='quarterly', period=365.25/4, fourier_order=5)\n",
    "\n",
    "        model.fit(train_df)\n",
    "        future = model.make_future_dataframe(periods=len(test_df), freq='QS' if time_granularity == 'quarterly' else 'AS')\n",
    "        forecast = model.predict(future)\n",
    "        predictions = forecast['yhat'].tail(len(test_df)).values\n",
    "        metrics = evaluate_model(test_df['y'], predictions, \"Prophet\")\n",
    "        return pd.Series(predictions, index=test_df['ds']), metrics\n",
    "    except Exception as e:\n",
    "        print(f\"Prophet training failed: {e}\")\n",
    "        return pd.Series([np.nan] * len(test_df), index=test_df['ds']), {'MAE': np.nan, 'RMSE': np.nan, 'MAPE': np.nan}\n",
    "\n",
    "def train_and_forecast_ets(train_df, test_df, time_granularity):\n",
    "    \"\"\"\n",
    "    Trains and forecasts using Exponential Smoothing (Holt-Winters).\n",
    "\n",
    "    Args:\n",
    "        train_df (pd.DataFrame): Training data with 'ds' and 'y'.\n",
    "        test_df (pd.DataFrame): Test data with 'ds' and 'y'.\n",
    "        time_granularity (str): 'quarterly' or 'annually'.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (pd.Series, dict) - Predicted values and evaluation metrics.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        train_series = train_df.set_index('ds')['y']\n",
    "        \n",
    "        # Infer frequency if possible, otherwise set to None\n",
    "        try:\n",
    "            freq = pd.infer_freq(train_series.index)\n",
    "        except ValueError:\n",
    "            freq = None\n",
    "        \n",
    "        # If frequency is not inferred, try to determine it based on time differences\n",
    "        if freq is None and len(train_series) > 1:\n",
    "            time_diff = train_series.index.to_series().diff().dropna()\n",
    "            if (time_diff.dt.days == 91).all():\n",
    "                freq = 'QS'\n",
    "            elif (time_diff.dt.days == 365).all():\n",
    "                freq = 'AS'\n",
    "        \n",
    "        # Set frequency if determined\n",
    "        if freq:\n",
    "            train_series.index.freq = freq\n",
    "        else:\n",
    "            print(\"ETS: Could not infer frequency.  Skipping model.\")\n",
    "            return pd.Series([np.nan] * len(test_df), index=test_df['ds']), {'MAE': np.nan, 'RMSE': np.nan, 'MAPE': np.nan}\n",
    "\n",
    "        seasonal_periods = 4 if time_granularity == 'quarterly' else 1\n",
    "\n",
    "        model = ExponentialSmoothing(\n",
    "            train_series,\n",
    "            seasonal_periods=seasonal_periods,\n",
    "            initialization_method=\"estimated\"\n",
    "        )\n",
    "        model_fit = model.fit()\n",
    "        predictions = model_fit.forecast(len(test_df))\n",
    "        metrics = evaluate_model(test_df['y'], predictions, \"ETS\")\n",
    "        return predictions, metrics\n",
    "    except Exception as e:\n",
    "        print(f\"ETS training failed: {e}\")\n",
    "        return pd.Series([np.nan] * len(test_df), index=test_df['ds']), {'MAE': np.nan, 'RMSE': np.nan, 'MAPE': np.nan}\n",
    "\n",
    "\n",
    "def create_time_features(df):\n",
    "    \"\"\"\n",
    "    Creates time-based features for ML models.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with a 'ds' (datetime) column.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with added time features.\n",
    "    \"\"\"\n",
    "    df['year'] = df['ds'].dt.year\n",
    "    df['quarter'] = df['ds'].dt.quarter\n",
    "    df['month'] = df['ds'].dt.month\n",
    "    df['dayofyear'] = df['ds'].dt.dayofyear\n",
    "    df['weekofyear'] = df['ds'].dt.isocalendar().week.astype(int)\n",
    "    return df\n",
    "\n",
    "def train_and_forecast_ml_model(train_df, test_df, model_type='RandomForest'):\n",
    "    \"\"\"\n",
    "    Trains and forecasts using a machine learning regressor (Random Forest or XGBoost).\n",
    "\n",
    "    Args:\n",
    "        train_df (pd.DataFrame): Training data with 'ds' and 'y'.\n",
    "        test_df (pd.DataFrame): Test data with 'ds' and 'y'.\n",
    "        model_type (str): 'RandomForest' or 'XGBoost'.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (pd.Series, dict) - Predicted values and evaluation metrics.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        train_features = create_time_features(train_df.copy())\n",
    "        test_features = create_time_features(test_df.copy())\n",
    "\n",
    "        features = ['year', 'quarter', 'month', 'dayofyear', 'weekofyear']\n",
    "        existing_features = [f for f in features if f in train_features.columns and f in test_features.columns]\n",
    "        if not existing_features:\n",
    "            print(f\"ML Model: No relevant time features found for training. Skipping {model_type}.\")\n",
    "            return pd.Series([np.nan] * len(test_df), index=test_df['ds']), {'MAE': np.nan, 'RMSE': np.nan, 'MAPE': np.nan}\n",
    "\n",
    "        X_train = train_features[existing_features]\n",
    "        y_train = train_features['y']\n",
    "        X_test = test_features[existing_features]\n",
    "\n",
    "        if model_type == 'RandomForest':\n",
    "            model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "            model_name = \"RandomForest\"\n",
    "        elif model_type == 'XGBoost':\n",
    "            model = XGBRegressor(n_estimators=100, random_state=42, objective='reg:squarederror')\n",
    "            model_name = \"XGBoost\"\n",
    "        else:\n",
    "            raise ValueError(\"model_type must be 'RandomForest' or 'XGBoost'.\")\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        predictions = pd.Series(predictions, index=test_df['ds'])\n",
    "        metrics = evaluate_model(test_df['y'], predictions, model_name)\n",
    "        return predictions, metrics\n",
    "    except Exception as e:\n",
    "        print(f\"{model_type} training failed: {e}\")\n",
    "        return pd.Series([np.nan] * len(test_df), index=test_df['ds']), {'MAE': np.nan, 'RMSE': np.nan, 'MAPE': np.nan}\n",
    "\n",
    "def train_and_forecast_naive(train_df, test_df):\n",
    "    \"\"\"\n",
    "    Trains and forecasts using a Naive (last value) model.\n",
    "\n",
    "    Args:\n",
    "        train_df (pd.DataFrame): Training data with 'ds' and 'y'.\n",
    "        test_df (pd.DataFrame): Test data with 'ds' and 'y'.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (pd.Series, dict) - Predicted values and evaluation metrics.\n",
    "    \"\"\"\n",
    "    if not train_df.empty:\n",
    "        last_value = train_df['y'].iloc[-1]\n",
    "        predictions = pd.Series([last_value] * len(test_df), index=test_df['ds'])\n",
    "    else:\n",
    "        predictions = pd.Series([np.nan] * len(test_df), index=test_df['ds'])\n",
    "    metrics = evaluate_model(test_df['y'], predictions, \"Naive\")\n",
    "    return predictions, metrics\n",
    "\n",
    "def plot_forecast(actual, train, predictions, title, forecast_horizon_label, filename):\n",
    "    \"\"\"\n",
    "    Plots the actual, training, and predicted values.\n",
    "\n",
    "    Args:\n",
    "        actual (pd.Series): Actual values (including train and test).\n",
    "        train (pd.Series): Training data values.\n",
    "        predictions (pd.Series): Predicted values.\n",
    "        title (str): Title of the plot.\n",
    "        forecast_horizon_label (str): Label for the forecast horizon (e.g., 'next 4 quarters').\n",
    "        filename (str): Name to save the plot.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(train.index, train, label='Training Data', color='blue')\n",
    "    plt.plot(actual.index, actual, label='Actual Data', color='green', linestyle='--')\n",
    "    plt.plot(predictions.index, predictions, label=f'Forecasted Data ({forecast_horizon_label})', color='red')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Ticket Count')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to orchestrate data loading, preprocessing, model training,\n",
    "    evaluation, selection, and forecasting using ITSM data.\n",
    "    \"\"\"\n",
    "    print(\"--- Loading and Processing ITSM Data ---\")\n",
    "    daily_incident_data = load_itsm_data(file_path=\"ITSM_data.csv\")\n",
    "\n",
    "    if daily_incident_data is None or daily_incident_data.empty:\n",
    "        print(\"No data loaded or processed from ITSM_data.csv. Exiting.\")\n",
    "        return\n",
    "\n",
    "    forecast_horizon_quarterly = 4\n",
    "    forecast_horizon_annually = 2\n",
    "\n",
    "    for granularity in ['quarterly', 'annually']:\n",
    "        print(f\"\\n--- Processing for {granularity.capitalize()} Granularity ---\")\n",
    "        processed_data_by_category = preprocess_data(daily_incident_data, time_granularity=granularity)\n",
    "\n",
    "        for category, df_agg in processed_data_by_category.items():\n",
    "            print(f\"\\n--- Forecasting for Category: {category} ({granularity.capitalize()}) ---\")\n",
    "\n",
    "            test_size = forecast_horizon_quarterly if granularity == 'quarterly' else forecast_horizon_annually\n",
    "            if len(df_agg) <= test_size + 2:\n",
    "                print(f\"Not enough data for {granularity} split for {category}. Skipping. (Need > {test_size+2} points, have {len(df_agg)})\")\n",
    "                continue\n",
    "\n",
    "            train_df = df_agg.iloc[:-test_size].copy()\n",
    "            test_df = df_agg.iloc[-test_size:].copy()\n",
    "\n",
    "            print(f\"Train data size: {len(train_df)}\")\n",
    "            print(f\"Test data size: {len(test_df)}\")\n",
    "\n",
    "            all_model_results = {}\n",
    "            all_model_predictions = {}\n",
    "\n",
    "            # Define seasonal_order outside the loop\n",
    "            sarima_seasonal_order = (1, 1, 0, 4)\n",
    "\n",
    "            naive_predictions, naive_metrics = train_and_forecast_naive(train_df, test_df)\n",
    "            all_model_results['Naive'] = naive_metrics\n",
    "            all_model_predictions['Naive'] = naive_predictions\n",
    "\n",
    "            sarima_order = (1,1,1)\n",
    "            sarima_predictions, sarima_metrics = train_and_forecast_arima(train_df, test_df, order=sarima_order, seasonal_order=sarima_seasonal_order)\n",
    "            all_model_results['SARIMA'] = sarima_metrics\n",
    "            all_model_predictions['SARIMA'] = sarima_predictions\n",
    "\n",
    "            prophet_predictions, prophet_metrics = train_and_forecast_prophet(train_df, test_df, granularity)\n",
    "            all_model_results['Prophet'] = prophet_metrics\n",
    "            all_model_predictions['Prophet'] = prophet_predictions\n",
    "\n",
    "            ets_predictions, ets_metrics = train_and_forecast_ets(train_df, test_df, granularity)\n",
    "            all_model_results['ETS'] = ets_metrics\n",
    "            all_model_predictions['ETS'] = ets_predictions\n",
    "\n",
    "            rf_predictions, rf_metrics = train_and_forecast_ml_model(train_df, test_df, 'RandomForest')\n",
    "            all_model_results['RandomForest'] = rf_metrics\n",
    "            all_model_predictions['RandomForest'] = rf_predictions\n",
    "\n",
    "            xgb_predictions, xgb_metrics = train_and_forecast_ml_model(train_df, test_df, 'XGBoost')\n",
    "            all_model_results['XGBoost'] = xgb_metrics\n",
    "            all_model_predictions['XGBoost'] = xgb_predictions\n",
    "\n",
    "            best_model_name = None\n",
    "            min_rmse = float('inf')\n",
    "\n",
    "            print(\"\\n--- Model Comparison ---\")\n",
    "            for model_name, metrics in all_model_results.items():\n",
    "                if not np.isnan(metrics['RMSE']) and metrics['RMSE'] < min_rmse:\n",
    "                    min_rmse = metrics['RMSE']\n",
    "                    best_model_name = model_name\n",
    "                print(f\"{model_name}: RMSE={metrics['RMSE']:.2f}, MAE={metrics['MAE']:.2f}, MAPE={metrics['MAPE']:.2f}%\")\n",
    "\n",
    "            if best_model_name:\n",
    "                print(f\"\\nBest model for {category} ({granularity}): {best_model_name} (RMSE: {min_rmse:.2f})\")\n",
    "            else:\n",
    "                print(f\"\\nCould not determine best model for {category} ({granularity}). All models failed or produced NaN RMSE.\")\n",
    "                continue\n",
    "\n",
    "            print(f\"\\n--- Forecasting Future Volumes with {best_model_name} ---\")\n",
    "\n",
    "            full_df = df_agg.copy()\n",
    "\n",
    "            future_periods = forecast_horizon_quarterly if granularity == 'quarterly' else forecast_horizon_annually\n",
    "            \n",
    "            last_date = full_df['ds'].max()\n",
    "            if granularity == 'quarterly':\n",
    "                future_dates = pd.date_range(start=last_date + pd.DateOffset(months=3), periods=future_periods, freq='QS')\n",
    "            else:\n",
    "                future_dates = pd.date_range(start=last_date + pd.DateOffset(years=1), periods=future_periods, freq='AS')\n",
    "            \n",
    "            future_df = pd.DataFrame({'ds': future_dates})\n",
    "\n",
    "\n",
    "            if best_model_name == 'Naive':\n",
    "                if not full_df.empty:\n",
    "                    final_forecast_predictions = pd.Series([full_df['y'].iloc[-1]] * future_periods, index=future_df['ds'])\n",
    "                else:\n",
    "                    final_forecast_predictions = pd.Series([np.nan] * future_periods, index=future_df['ds'])\n",
    "            elif best_model_name == 'SARIMA':\n",
    "                full_series = full_df.set_index('ds')['y']\n",
    "                \n",
    "                # Infer frequency if possible, otherwise set to None\n",
    "                try:\n",
    "                    freq = pd.infer_freq(full_series.index)\n",
    "                except ValueError:\n",
    "                    freq = None\n",
    "                \n",
    "                # If frequency is not inferred, try to determine it based on time differences\n",
    "                if freq is None and len(full_series) > 1:\n",
    "                    time_diff = full_series.index.to_series().diff().dropna()\n",
    "                    if (time_diff.dt.days == 91).all():\n",
    "                        freq = 'QS'\n",
    "                    elif (time_diff.dt.days == 365).all():\n",
    "                        freq = 'AS'\n",
    "                \n",
    "                # Set frequency if determined\n",
    "                if freq:\n",
    "                    full_series.index.freq = freq\n",
    "                else:\n",
    "                    print(\"SARIMA: Could not infer frequency for final forecast.  Skipping model.\")\n",
    "                    final_forecast_predictions = pd.Series([np.nan] * future_periods, index=future_df['ds'])\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    model = ARIMA(full_series, order=sarima_order, seasonal_order=sarima_seasonal_order, enforce_stationarity=False, enforce_invertibility=False)\n",
    "                    model_fit = model.fit()\n",
    "                    final_forecast_predictions = model_fit.predict(start=len(full_df), end=len(full_df) + future_periods - 1)\n",
    "                    final_forecast_predictions.index = future_df['ds']\n",
    "                except Exception as e:\n",
    "                    print(f\"SARIMA final forecast failed: {e}\")\n",
    "                    final_forecast_predictions = pd.Series([np.nan] * future_periods, index=future_df['ds'])\n",
    "            elif best_model_name == 'Prophet':\n",
    "                #from prophet import Prophet\n",
    "                from prophet import Prophet\n",
    "                model = Prophet(\n",
    "                    yearly_seasonality=True,\n",
    "                )\n",
    "                if granularity == 'quarterly':\n",
    "                    model.add_seasonality(name='quarterly', period=365.25/4, fourier_order=5)\n",
    "                model.fit(full_df)\n",
    "                future = model.make_future_dataframe(periods=future_periods, freq='QS' if granularity == 'quarterly' else 'AS')\n",
    "                forecast = model.predict(future)\n",
    "                final_forecast_predictions = forecast['yhat'].tail(future_periods)\n",
    "                final_forecast_predictions = pd.Series(final_forecast_predictions.values, index=future_df['ds'])\n",
    "            elif best_model_name == 'ETS':\n",
    "                full_series = full_df.set_index('ds')['y']\n",
    "                \n",
    "                # Infer frequency if possible, otherwise set to None\n",
    "                try:\n",
    "                    freq = pd.infer_freq(full_series.index)\n",
    "                except ValueError:\n",
    "                    freq = None\n",
    "                \n",
    "                # If frequency is not inferred, try to determine it based on time differences\n",
    "                if freq is None and len(full_series) > 1:\n",
    "                    time_diff = full_series.index.to_series().diff().dropna()\n",
    "                    if (time_diff.dt.days == 91).all():\n",
    "                        freq = 'QS'\n",
    "                    elif (time_diff.dt.days == 365).all():\n",
    "                        freq = 'AS'\n",
    "                \n",
    "                # Set frequency if determined\n",
    "                if freq:\n",
    "                    full_series.index.freq = freq\n",
    "                else:\n",
    "                    print(\"ETS: Could not infer frequency for final forecast.  Skipping model.\")\n",
    "                    final_forecast_predictions = pd.Series([np.nan] * future_periods, index=future_df['ds'])\n",
    "                    continue\n",
    "\n",
    "                seasonal_periods = 4 if granularity == 'quarterly' else 1\n",
    "                try:\n",
    "                    model = ExponentialSmoothing(\n",
    "                        full_series,\n",
    "                        seasonal_periods=seasonal_periods,\n",
    "                        initialization_method=\"estimated\"\n",
    "                    )\n",
    "                    model_fit = model.fit()\n",
    "                    final_forecast_predictions = model_fit.forecast(future_periods)\n",
    "                    final_forecast_predictions.index = future_df['ds']\n",
    "                except Exception as e:\n",
    "                    print(f\"ETS final forecast failed: {e}\")\n",
    "                    final_forecast_predictions = pd.Series([np.nan] * future_periods, index=future_df['ds'])\n",
    "            elif best_model_name in ['RandomForest', 'XGBoost']:\n",
    "                full_features = create_time_features(full_df.copy())\n",
    "                future_features = create_time_features(future_df.copy())\n",
    "                features = ['year', 'quarter', 'month', 'dayofyear', 'weekofyear']\n",
    "                \n",
    "                existing_features_full = [f for f in features if f in full_features.columns]\n",
    "                existing_features_future = [f for f in features if f in future_features.columns]\n",
    "\n",
    "                if not existing_features_full or not existing_features_future:\n",
    "                    print(f\"ML Model final forecast: Missing features for training or prediction. Skipping {best_model_name}.\")\n",
    "                    final_forecast_predictions = pd.Series([np.nan] * future_periods, index=future_df['ds'])\n",
    "                else:\n",
    "                    X_full = full_features[existing_features_full]\n",
    "                    y_full = full_features['y']\n",
    "                    X_future = future_features[existing_features_future]\n",
    "\n",
    "                    if best_model_name == 'RandomForest':\n",
    "                        model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "                    else:\n",
    "                        model = XGBRegressor(n_estimators=100, random_state=42, objective='reg:squarederror')\n",
    "                    \n",
    "                    model.fit(X_full, y_full)\n",
    "                    final_forecast_predictions = pd.Series(model.predict(X_future), index=future_df['ds'])\n",
    "            else:\n",
    "                final_forecast_predictions = pd.Series([np.nan] * future_periods, index=future_df['ds'])\n",
    "\n",
    "            print(f\"Forecasted {future_periods} {granularity} periods for {category}:\")\n",
    "            print(final_forecast_predictions)\n",
    "\n",
    "            actual_data_for_plot = df_agg.set_index('ds')['y']\n",
    "            train_data_for_plot = train_df.set_index('ds')['y']\n",
    "            \n",
    "            combined_series = pd.concat([actual_data_for_plot, final_forecast_predictions])\n",
    "            \n",
    "            plot_forecast(\n",
    "                actual=combined_series,\n",
    "                train=train_data_for_plot,\n",
    "                predictions=final_forecast_predictions,\n",
    "                title=f'{category} Ticket Volume Forecast ({granularity.capitalize()}) - Best Model: {best_model_name}',\n",
    "                forecast_horizon_label=f'next {future_periods} {granularity}',\n",
    "                filename=f'forecast_{category}_{granularity}.png'\n",
    "            )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7edf15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
