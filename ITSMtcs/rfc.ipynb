{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a26babdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ITSM_data.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashutosh\\AppData\\Local\\Temp\\ipykernel_14892\\3839785196.py:19: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data loaded. Performing cleaning and feature derivation...\n",
      "Data cleaning and target derivation complete.\n",
      "\n",
      "--- Sample ITSM Data (after initial cleaning) ---\n",
      "     CI_Name          CI_Cat              CI_Subcat        WBS Incident_ID  \\\n",
      "0  SUB000508  subapplication  Web Based Application  WBS000162   IM0000004   \n",
      "1  WBA000124     application  Web Based Application  WBS000088   IM0000005   \n",
      "2  DTA000024     application    Desktop Application  WBS000092   IM0000006   \n",
      "3  WBA000124     application  Web Based Application  WBS000088   IM0000011   \n",
      "4  WBA000124     application  Web Based Application  WBS000088   IM0000012   \n",
      "\n",
      "   Status  Impact  Urgency  Priority  number_cnt  ...        Close_Time  \\\n",
      "0  Closed     4.0      4.0       4.0    0.601292  ...   4/11/2023 13:51   \n",
      "1  Closed     3.0      3.0       3.0    0.415050  ...   2/12/2023 12:36   \n",
      "2  Closed     4.0      3.0       4.0    0.517551  ...  13-01-2024 15:13   \n",
      "3  Closed     4.0      4.0       4.0    0.642927  ...  14-11-2023 09:31   \n",
      "4  Closed     4.0      4.0       4.0    0.345258  ...   8/11/2023 13:55   \n",
      "\n",
      "  Handle_Time_hrs                  Closure_Code  No_of_Related_Interactions  \\\n",
      "0        0.465556                         Other                         1.0   \n",
      "1        0.465556                      Software                         1.0   \n",
      "2        0.465556  No error - works as designed                         1.0   \n",
      "3        0.465556                Operator error                         1.0   \n",
      "4        0.465556                         Other                         1.0   \n",
      "\n",
      "  Related_Interaction No_of_Related_Incidents No_of_Related_Changes  \\\n",
      "0           SD0000007                     2.0                   1.0   \n",
      "1           SD0000011                     1.0                   1.0   \n",
      "2           SD0000017                     1.0                   1.0   \n",
      "3           SD0000025                     1.0                   1.0   \n",
      "4           SD0000029                     1.0                   1.0   \n",
      "\n",
      "  Related_Change  rfc_successful is_misconfigured_proxy  \n",
      "0            NaN               1                      1  \n",
      "1            NaN               1                      1  \n",
      "2            NaN               1                      0  \n",
      "3            NaN               1                      1  \n",
      "4            NaN               1                      0  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "Total records loaded: 46606\n",
      "Starting data preprocessing...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "For a sparse output, all columns should be a numeric or convertible to a numeric.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\compose\\_column_transformer.py:857\u001b[0m, in \u001b[0;36mColumnTransformer._hstack\u001b[1;34m(self, Xs)\u001b[0m\n\u001b[0;32m    853\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;66;03m# since all columns should be numeric before stacking them\u001b[39;00m\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# in a sparse matrix, `check_array` is used for the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# dtype conversion if necessary.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m     converted_Xs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    858\u001b[0m         check_array(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    859\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m Xs\n\u001b[0;32m    860\u001b[0m     ]\n\u001b[0;32m    861\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\compose\\_column_transformer.py:858\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    853\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;66;03m# since all columns should be numeric before stacking them\u001b[39;00m\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# in a sparse matrix, `check_array` is used for the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# dtype conversion if necessary.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     converted_Xs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 858\u001b[0m         check_array(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    859\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m Xs\n\u001b[0;32m    860\u001b[0m     ]\n\u001b[0;32m    861\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 915\u001b[0m         array \u001b[38;5;241m=\u001b[39m _asarray_with_order(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 380\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ashutosh\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:2070\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2069\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m-> 2070\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'SUB000508'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 282\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28mprint\u001b[39m(itsm_data\u001b[38;5;241m.\u001b[39mhead())\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal records loaded: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(itsm_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    279\u001b[0m X_rfc_processed, y_rfc_target, X_asset_processed, y_asset_misconfigured_target, \\\n\u001b[0;32m    280\u001b[0m rfc_preprocessor_fitted, asset_preprocessor_fitted, \\\n\u001b[0;32m    281\u001b[0m original_itsm_cols_for_pred, original_asset_agg_cols_for_pred \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m--> 282\u001b[0m     preprocess_data(itsm_data)\n\u001b[0;32m    284\u001b[0m rfc_prediction_model \u001b[38;5;241m=\u001b[39m train_rfc_prediction_model(X_rfc_processed, y_rfc_target)\n\u001b[0;32m    286\u001b[0m anomaly_detection_model \u001b[38;5;241m=\u001b[39m train_anomaly_detection_model(X_asset_processed, y_asset_misconfigured_target)\n",
      "Cell \u001b[1;32mIn[3], line 101\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[1;34m(itsm_df)\u001b[0m\n\u001b[0;32m     92\u001b[0m preprocessor_rfc \u001b[38;5;241m=\u001b[39m ColumnTransformer(\n\u001b[0;32m     93\u001b[0m     transformers\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     94\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum\u001b[39m\u001b[38;5;124m'\u001b[39m, StandardScaler(), numerical_features_rfc),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     97\u001b[0m     remainder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Handle any unexpected columns\u001b[39;00m\n\u001b[0;32m     98\u001b[0m )\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# Fit and transform the data for RFC prediction\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m X_rfc \u001b[38;5;241m=\u001b[39m preprocessor_rfc\u001b[38;5;241m.\u001b[39mfit_transform(itsm_df)\n\u001b[0;32m    102\u001b[0m y_rfc \u001b[38;5;241m=\u001b[39m itsm_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrfc_successful\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# Prepare asset data for anomaly detection\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\compose\\_column_transformer.py:778\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    775\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_output(Xs)\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_record_output_indices(Xs)\n\u001b[1;32m--> 778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hstack(\u001b[38;5;28mlist\u001b[39m(Xs))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\compose\\_column_transformer.py:862\u001b[0m, in \u001b[0;36mColumnTransformer._hstack\u001b[1;34m(self, Xs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         converted_Xs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    858\u001b[0m             check_array(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    859\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m Xs\n\u001b[0;32m    860\u001b[0m         ]\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 862\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    863\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor a sparse output, all columns should \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    864\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbe a numeric or convertible to a numeric.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    867\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39mhstack(converted_Xs)\u001b[38;5;241m.\u001b[39mtocsr()\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: For a sparse output, all columns should be a numeric or convertible to a numeric."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def load_itsm_data(file_path=\"ITSM_data.csv\"):\n",
    "    \"\"\"\n",
    "    Loads ITSM data from a CSV file and performs initial cleaning.\n",
    "    This includes parsing 'Handle_Time_hrs' and deriving target variables.\n",
    "    \"\"\"\n",
    "    print(f\"Loading data from {file_path}...\")\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {file_path} not found. Please ensure the file is in the correct directory.\")\n",
    "        return pd.DataFrame()  # Return empty DataFrame on error\n",
    "\n",
    "    print(\"Initial data loaded. Performing cleaning and feature derivation...\")\n",
    "\n",
    "    def parse_handle_time(time_str):\n",
    "        if pd.isna(time_str):\n",
    "            return np.nan\n",
    "        try:\n",
    "            # Improved handling of comma as decimal separator\n",
    "            time_str = time_str.replace(',', '.')  # Replace comma with dot for decimal\n",
    "            return float(time_str)\n",
    "        except ValueError:\n",
    "            return np.nan\n",
    "\n",
    "    if 'Handle_Time_hrs' in df.columns:\n",
    "        df['Handle_Time_hrs'] = df['Handle_Time_hrs'].apply(parse_handle_time)\n",
    "\n",
    "    numerical_cols_to_fill = [\n",
    "        'Impact', 'Urgency', 'Priority', 'number_cnt', 'No_of_Reassignments',\n",
    "        'No_of_Related_Interactions', 'No_of_Related_Incidents', 'No_of_Related_Changes',\n",
    "        'Handle_Time_hrs'\n",
    "    ]\n",
    "    for col in numerical_cols_to_fill:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "    if 'Status' in df.columns:\n",
    "        df['rfc_successful'] = df['Status'].apply(lambda x: 1 if x == 'Closed' else 0)\n",
    "    else:\n",
    "        df['rfc_successful'] = 0  # Default if Status missing\n",
    "\n",
    "    # Derive misconfiguration proxy flag\n",
    "    df['is_misconfigured_proxy'] = 0\n",
    "    for col in ['No_of_Related_Incidents', 'No_of_Related_Changes', 'No_of_Reassignments']:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0  # Fill missing columns with 0\n",
    "\n",
    "    # Use .loc for assignment to avoid SettingWithCopyWarning\n",
    "    df.loc[\n",
    "        (df['No_of_Related_Incidents'] > df['No_of_Related_Incidents'].quantile(0.95)) |\n",
    "        (df['No_of_Related_Changes'] > df['No_of_Related_Changes'].quantile(0.95)) |\n",
    "        (df['No_of_Reassignments'] > df['No_of_Reassignments'].quantile(0.95)),\n",
    "        'is_misconfigured_proxy'\n",
    "    ] = 1\n",
    "\n",
    "    print(\"Data cleaning and target derivation complete.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess_data(itsm_df):\n",
    "    \"\"\"\n",
    "    Preprocesses the ITSM DataFrame for both RFC prediction and asset anomaly detection.\n",
    "    Handles categorical encoding and numerical scaling.\n",
    "    \"\"\"\n",
    "    print(\"Starting data preprocessing...\")\n",
    "\n",
    "    categorical_features_rfc = [\n",
    "        'CI_Cat', 'CI_Subcat', 'Status', 'Impact', 'Urgency', 'Category', 'Alert_Status', 'Closure_Code'\n",
    "    ]\n",
    "    numerical_features_rfc = [\n",
    "        'Priority', 'number_cnt', 'No_of_Reassignments', 'Handle_Time_hrs',\n",
    "        'No_of_Related_Interactions', 'No_of_Related_Incidents', 'No_of_Related_Changes'\n",
    "    ]\n",
    "\n",
    "    # Filter features to only include columns that exist in the DataFrame\n",
    "    categorical_features_rfc = [f for f in categorical_features_rfc if f in itsm_df.columns]\n",
    "    numerical_features_rfc = [f for f in numerical_features_rfc if f in itsm_df.columns]\n",
    "\n",
    "    # Create preprocessor for RFC prediction\n",
    "    preprocessor_rfc = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_features_rfc),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_rfc)\n",
    "        ],\n",
    "        remainder='passthrough'  # Handle any unexpected columns\n",
    "    )\n",
    "\n",
    "    # Fit and transform the data for RFC prediction\n",
    "    X_rfc = preprocessor_rfc.fit_transform(itsm_df)\n",
    "    y_rfc = itsm_df['rfc_successful']\n",
    "\n",
    "    # Prepare asset data for anomaly detection\n",
    "    asset_group_cols = ['CI_Name', 'CI_Cat', 'CI_Subcat']\n",
    "    asset_agg_cols = [\n",
    "        'No_of_Related_Interactions', 'No_of_Related_Incidents',\n",
    "        'No_of_Related_Changes', 'No_of_Reassignments', 'Handle_Time_hrs'\n",
    "    ]\n",
    "\n",
    "    # Filter features to only include columns that exist in the DataFrame\n",
    "    asset_group_cols = [col for col in asset_group_cols if col in itsm_df.columns]\n",
    "    asset_agg_cols = [col for col in asset_agg_cols if col in itsm_df.columns]\n",
    "\n",
    "    # Group by asset features and aggregate\n",
    "    asset_df_for_anomaly = itsm_df.groupby(asset_group_cols)[asset_agg_cols].mean().reset_index()\n",
    "\n",
    "    # Derive misconfiguration proxy flag\n",
    "    asset_df_for_anomaly['is_misconfigured_proxy'] = 0\n",
    "    asset_df_for_anomaly.loc[\n",
    "        (asset_df_for_anomaly['No_of_Related_Incidents'] > asset_df_for_anomaly['No_of_Related_Incidents'].quantile(0.95)) |\n",
    "        (asset_df_for_anomaly['No_of_Related_Changes'] > asset_df_for_anomaly['No_of_Related_Changes'].quantile(0.95)) |\n",
    "        (asset_df_for_anomaly['No_of_Reassignments'] > asset_df_for_anomaly['No_of_Reassignments'].quantile(0.95)),\n",
    "        'is_misconfigured_proxy'\n",
    "    ] = 1\n",
    "\n",
    "    y_asset_misconfigured = asset_df_for_anomaly['is_misconfigured_proxy']\n",
    "\n",
    "    numerical_features_asset = asset_agg_cols\n",
    "    categorical_features_asset = [f for f in ['CI_Cat', 'CI_Subcat'] if f in asset_df_for_anomaly.columns]\n",
    "\n",
    "    # Create preprocessor for asset anomaly detection\n",
    "    preprocessor_asset = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_features_asset),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_asset)\n",
    "        ],\n",
    "        remainder='drop'\n",
    "    )\n",
    "\n",
    "    # Fit and transform the data for asset anomaly detection\n",
    "    X_asset = preprocessor_asset.fit_transform(asset_df_for_anomaly.drop(columns=['is_misconfigured_proxy'], errors='ignore'))\n",
    "\n",
    "    print(\"Data preprocessing complete.\")\n",
    "    return (X_rfc, y_rfc, X_asset, y_asset_misconfigured,\n",
    "            preprocessor_rfc, preprocessor_asset,\n",
    "            itsm_df.columns.tolist(), asset_agg_cols + categorical_features_asset)\n",
    "\n",
    "\n",
    "def train_rfc_prediction_model(X_rfc, y_rfc):\n",
    "    \"\"\"\n",
    "    Trains a RandomForestClassifier model to predict RFC success/failure.\n",
    "    \"\"\"\n",
    "    print(\"Training RFC Failure Prediction Model...\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_rfc, y_rfc, test_size=0.2, random_state=42, stratify=y_rfc\n",
    "    )\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    print(\"\\n--- RFC Prediction Model Evaluation ---\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Failed', 'Successful']))\n",
    "    print(f\"ROC AUC Score: {roc_auc_score(y_test, y_proba):.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['Predicted Failed', 'Predicted Successful'],\n",
    "                yticklabels=['Actual Failed', 'Actual Successful'])\n",
    "    plt.title('RFC Prediction Confusion Matrix')\n",
    "    plt.ylabel('Actual Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()  # Adjust layout to prevent labels from overlapping\n",
    "    plt.show()\n",
    "\n",
    "    print(\"RFC Failure Prediction Model training complete.\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_anomaly_detection_model(X_asset, y_asset_misconfigured):\n",
    "    \"\"\"\n",
    "    Trains an IsolationForest model to detect anomalies (misconfigurations) in asset data.\n",
    "    \"\"\"\n",
    "    print(\"Training Asset Misconfiguration Anomaly Detection Model...\")\n",
    "\n",
    "    # Handle cases where there are no misconfigured assets\n",
    "    if y_asset_misconfigured.sum() == 0:\n",
    "        print(\"No misconfigured assets found. Setting contamination to 'auto'.\")\n",
    "        contamination_rate = 'auto'\n",
    "    else:\n",
    "        contamination_rate = y_asset_misconfigured.value_counts(normalize=True).get(1, 0)\n",
    "        print(f\"Estimated contamination rate for IsolationForest: {contamination_rate:.4f}\")\n",
    "\n",
    "    model = IsolationForest(random_state=42, contamination=contamination_rate)\n",
    "    model.fit(X_asset)\n",
    "\n",
    "    anomaly_scores = model.decision_function(X_asset)\n",
    "    anomaly_predictions = model.predict(X_asset)\n",
    "    predicted_misconfigured = np.where(anomaly_predictions == -1, 1, 0)\n",
    "\n",
    "    print(\"\\n--- Anomaly Detection Model Evaluation (on training data) ---\")\n",
    "    print(\"Classification Report (Anomaly Detection):\")\n",
    "    print(classification_report(y_asset_misconfigured, predicted_misconfigured, target_names=['Normal', 'Misconfigured']))\n",
    "    print(\"Confusion Matrix (Anomaly Detection):\")\n",
    "    print(confusion_matrix(y_asset_misconfigured, predicted_misconfigured))\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(anomaly_scores, bins=50, kde=True)\n",
    "    plt.title('Distribution of Anomaly Scores')\n",
    "    plt.xlabel('Anomaly Score (Lower = More Anomalous)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Asset Misconfiguration Anomaly Detection Model training complete.\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict_risks(new_itsm_record, rfc_model, anomaly_model,\n",
    "                  rfc_preprocessor, asset_preprocessor,\n",
    "                  original_itsm_cols, original_asset_agg_cols):\n",
    "    \"\"\"\n",
    "    Predicts RFC success/failure and detects asset misconfigurations for a new ITSM record.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Making Predictions for New Data ---\")\n",
    "\n",
    "    if not isinstance(new_itsm_record, pd.DataFrame):\n",
    "        new_itsm_record = pd.DataFrame([new_itsm_record])\n",
    "\n",
    "    # Ensure all original columns are present for RFC prediction\n",
    "    rfc_input_df = new_itsm_record.reindex(columns=original_itsm_cols, fill_value=np.nan)\n",
    "\n",
    "    # Transform the new data using the preprocessor\n",
    "    X_new_rfc = rfc_preprocessor.transform(rfc_input_df)\n",
    "\n",
    "    rfc_prediction = rfc_model.predict(X_new_rfc)\n",
    "    rfc_probability = rfc_model.predict_proba(X_new_rfc)[:, 1]\n",
    "\n",
    "    # Prepare asset features for anomaly detection\n",
    "    # Create a DataFrame with only the required columns, filling missing columns with NaN\n",
    "    asset_features_for_pred = new_itsm_record.reindex(columns=original_asset_agg_cols)\n",
    "    asset_features_for_pred = asset_features_for_pred.fillna(asset_features_for_pred.median())\n",
    "\n",
    "    X_new_asset = asset_preprocessor.transform(asset_features_for_pred)\n",
    "\n",
    "    anomaly_score = anomaly_model.decision_function(X_new_asset)\n",
    "    anomaly_label = anomaly_model.predict(X_new_asset)\n",
    "\n",
    "    rfc_outcome = \"Successful\" if rfc_prediction[0] == 1 else \"Failed\"\n",
    "    asset_anomaly = \"Misconfigured (Anomaly Detected)\" if anomaly_label[0] == -1 else \"Normal Configuration\"\n",
    "\n",
    "    incident_id = new_itsm_record['Incident_ID'].iloc[0] if 'Incident_ID' in new_itsm_record.columns else \"Unknown\"\n",
    "    ci_name = new_itsm_record['CI_Name'].iloc[0] if 'CI_Name' in new_itsm_record.columns else \"Unknown\"\n",
    "\n",
    "    print(f\"\\nIncident ID: {incident_id}\")\n",
    "    print(f\"CI Name: {ci_name}\")\n",
    "    print(f\"Predicted RFC Outcome: {rfc_outcome} (Probability of Success: {rfc_probability[0]:.2f})\")\n",
    "    print(f\"Asset Configuration Status: {asset_anomaly} (Anomaly Score: {anomaly_score[0]:.2f})\")\n",
    "\n",
    "    return rfc_outcome, rfc_probability[0], asset_anomaly, anomaly_score[0]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    itsm_data = load_itsm_data(file_path=\"ITSM_data.csv\")\n",
    "\n",
    "    if itsm_data.empty:\n",
    "        print(\"Exiting due to data loading error.\")\n",
    "    else:\n",
    "        print(\"\\n--- Sample ITSM Data (after initial cleaning) ---\")\n",
    "        print(itsm_data.head())\n",
    "        print(f\"Total records loaded: {len(itsm_data)}\")\n",
    "\n",
    "        X_rfc_processed, y_rfc_target, X_asset_processed, y_asset_misconfigured_target, \\\n",
    "        rfc_preprocessor_fitted, asset_preprocessor_fitted, \\\n",
    "        original_itsm_cols_for_pred, original_asset_agg_cols_for_pred = \\\n",
    "            preprocess_data(itsm_data)\n",
    "\n",
    "        rfc_prediction_model = train_rfc_prediction_model(X_rfc_processed, y_rfc_target)\n",
    "\n",
    "        anomaly_detection_model = train_anomaly_detection_model(X_asset_processed, y_asset_misconfigured_target)\n",
    "\n",
    "        print(\"\\n--- Demonstrating Predictions for New ITSM Records ---\")\n",
    "\n",
    "        new_itsm_record_1 = {\n",
    "            'CI_Cat': 'application',\n",
    "            'CI_Subcat': 'Server Based Application',\n",
    "            'CI_Name': 'ServerApp01',\n",
    "            'WBS': 'WBS000073',\n",
    "            'Priority': 1,\n",
    "            'number_cnt': 0.5,\n",
    "            'Category': 'incident',\n",
    "            'KB_number': 'KM0000000',\n",
    "            'Alert_Status': 'active',\n",
    "            'Open_Time': '25-07-2025 10:00',\n",
    "            'Reopen_Time': np.nan,\n",
    "            'Resolved_Time': np.nan,\n",
    "            'Close_Time': np.nan,\n",
    "            'Closure_Code': np.nan,\n",
    "            'No_of_Related_Interactions': 5,\n",
    "            'No_of_Related_Changes': 3,\n",
    "            'No_of_Related_Incidents': 0,\n",
    "            'No_of_Reassignments': 0,\n",
    "            'Handle_Time_hrs': np.nan,\n",
    "            'Related_Change': np.nan,\n",
    "            'Status': 'Open',\n",
    "            'Impact': 3,\n",
    "            'Urgency': 3,\n",
    "            'Incident_ID': 'IM0000001'\n",
    "        }\n",
    "        predict_risks(new_itsm_record_1,\n",
    "                      rfc_prediction_model, anomaly_detection_model,\n",
    "                      rfc_preprocessor_fitted, asset_preprocessor_fitted,\n",
    "                      original_itsm_cols_for_pred, original_asset_agg_cols_for_pred)\n",
    "\n",
    "        new_itsm_record_2 = {\n",
    "            'CI_Cat': 'application',\n",
    "            'CI_Subcat': 'Web Based Application',\n",
    "            'CI_Name': 'WebApp01',\n",
    "            'WBS': 'WBS000088',\n",
    "            'Incident_ID': 'IM8888888',\n",
    "            'Status': 'Closed',\n",
    "            'Impact': 4,\n",
    "            'Urgency': 4,\n",
    "            'Priority': 4,\n",
    "            'number_cnt': 0.1,\n",
    "            'Category': 'incident',\n",
    "            'KB_number': 'KM0000000',\n",
    "            'Alert_Status': 'closed',\n",
    "            'No_of_Reassignments': 1,\n",
    "            'Open_Time': '25-07-2025 10:00',\n",
    "            'Reopen_Time': np.nan,\n",
    "            'Resolved_Time': '25-07-2025 11:00',\n",
    "            'Close_Time': '25-07-2025 11:05',\n",
    "            'Handle_Time_hrs': 1.0,\n",
    "            'Closure_Code': 'Software',\n",
    "            'No_of_Related_Interactions': 0,\n",
    "            'No_of_Related_Incidents': 0,\n",
    "            'No_of_Related_Changes': 0,\n",
    "            'Related_Change': np.nan\n",
    "        }\n",
    "        predict_risks(new_itsm_record_2,\n",
    "                      rfc_prediction_model, anomaly_detection_model,\n",
    "                      rfc_preprocessor_fitted, asset_preprocessor_fitted,\n",
    "                      original_itsm_cols_for_pred, original_asset_agg_cols_for_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c6e668",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
